# sinaweibo_spider

Sinaweibo scrapy, get url, contents and reviews. 

1.爬取新浪微博的微博内容及评论（包括网址），也可按需爬取其他信息，如性别、地址、关注、粉丝等。

2.数据存储在weibodata.txt，包括：序号、网址、正文及评论，如：

'''

1.***URL:http://weibo.cn/comment/D7BXruIn1?rl=1

Content:

:庭审结束，幸运追回失窃物品。感谢丹麦警方高效办案、丹麦驻华使馆的督促和涵哥的仗义、感谢ecco的鼎力相助、和所有关注此事的朋友们、特别感谢中国驻丹麦大使馆领事部倾力帮助和全力推进！圣诞将至，祝到丹麦旅游的朋友顺顺利利，遇到困难请与使领馆联系，之前我方得到使馆号码有误，有效联系方式如下 ​​​

Review:

新骗局！ ！！在微博会有一群假baby说给他的评论点赞！你私信他，他就给你转100元，你私信他会自动回复一个. 借贷宝 .  要你下载那个就可以获得20元，然后里面会通过注册后你认证的点头视频和你的银行卡身份证盗取后去贷款！请不要贪小便宜！赞我顶上去不要让其他人受害！！！转

一切都好就好！[鲜花][鲜花][鲜花]

涛姐打算什么时候草粉

一定要注意安全呀！

得多谢涵哥的仗义

'''


3.主要依赖：Python2，redis，scrapy。

4.主要方法：

a)爬取手机端数据，初始使用多个agent、微博ID，账号，若账号足够多，理论上可以不限制爬取间隔时间(由于只有一个账号，设置了爬取间隔，在cookies.py设置)；

b)使用redis存储爬取的网址queue.py；

c)使用redis查重，防止相同ID多次爬取dupefilter.py；

d)从初始 http://weibo.cn/ID/profile 开始爬取，得到微博评论网址，抓取数据；并且通过获得粉丝及关注的人ID，扩大爬虫范围。

部分数据在weibodata.txt展示。
